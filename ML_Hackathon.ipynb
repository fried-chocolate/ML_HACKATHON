{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BlZqHzVvxRS",
        "outputId": "901593c8-1d60-42d6-97a6-5f639c6e3ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for corpus: /content/corpus.txt\n",
            "Looking for test  : /content/test.txt\n"
          ]
        }
      ],
      "source": [
        "# --- Cell 1: Setup & Imports ---\n",
        "import os, random, time\n",
        "from collections import Counter, defaultdict\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Set, Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Paths (put corpus.txt and test.txt next to this notebook)\n",
        "DATA_DIR = os.getcwd()\n",
        "CORPUS_PATH = os.path.join(DATA_DIR, \"corpus.txt\")\n",
        "TEST_PATH   = os.path.join(DATA_DIR, \"test.txt\")\n",
        "\n",
        "print(\"Looking for corpus:\", CORPUS_PATH)\n",
        "print(\"Looking for test  :\", TEST_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 2: Load & Clean Data + Quick Stats ---\n",
        "\n",
        "from typing import List\n",
        "\n",
        "def load_word_list(path: str) -> List[str]:\n",
        "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        words = [w.strip().lower() for w in f if w.strip()]\n",
        "    # keep only a–z words per rules\n",
        "    return [w for w in words if all(\"a\" <= ch <= \"z\" for ch in w)]\n",
        "\n",
        "corpus_words = load_word_list(CORPUS_PATH)\n",
        "test_words   = load_word_list(TEST_PATH)\n",
        "\n",
        "print(f\"Loaded corpus words: {len(corpus_words)}\")\n",
        "print(f\"Loaded test words  : {len(test_words)}\")\n",
        "\n",
        "# peek a few\n",
        "print(\"\\nSample corpus:\", corpus_words[:10])\n",
        "print(\"Sample test  :\", test_words[:10])\n",
        "\n",
        "# length distribution\n",
        "lens = pd.Series([len(w) for w in corpus_words], name=\"length\")\n",
        "print(\"\\nCorpus length stats:\\n\", lens.describe())\n",
        "\n",
        "# plot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.hist(lens, bins=range(1, lens.max()+2), edgecolor=\"black\")\n",
        "plt.xlabel(\"Word Length\"); plt.ylabel(\"Count\"); plt.title(\"Corpus Word Length Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "Wvc8s9iuypjS",
        "outputId": "18efdd7b-32ea-459f-cd19-928e70db89a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded corpus words: 49979\n",
            "Loaded test words  : 2000\n",
            "\n",
            "Sample corpus: ['suburbanize', 'asmack', 'hypotypic', 'promoderationist', 'consonantly', 'philatelically', 'cacomelia', 'thicklips', 'luciferase', 'cinematography']\n",
            "Sample test  : ['marmar', 'janet', 'dentistical', 'troveless', 'unnotify', 'gastrostenosis', 'preaffiliation', 'obpyriform', 'veratrinize', 'protection']\n",
            "\n",
            "Corpus length stats:\n",
            " count    49979.000000\n",
            "mean         9.497669\n",
            "std          2.958091\n",
            "min          1.000000\n",
            "25%          7.000000\n",
            "50%          9.000000\n",
            "75%         11.000000\n",
            "max         24.000000\n",
            "Name: length, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 3: Train Hidden Markov Model (Letter-Bigram) ---\n",
        "\n",
        "ALPH = [chr(ord(\"a\")+i) for i in range(26)]\n",
        "A2I  = {ch:i for i,ch in enumerate(ALPH)}\n",
        "START, END = \"^\", \"$\"\n",
        "\n",
        "def train_bigram_hmm(words, add_k: float = 1.0):\n",
        "    \"\"\"Train bigram transitions P(next | current) with add-k smoothing.\"\"\"\n",
        "    from collections import Counter, defaultdict\n",
        "    trans_counts = defaultdict(Counter)\n",
        "    for w in words:\n",
        "        seq = [START] + list(w) + [END]\n",
        "        for a, b in zip(seq[:-1], seq[1:]):\n",
        "            trans_counts[a][b] += 1\n",
        "\n",
        "    states = [START] + ALPH + [END]\n",
        "    T = {s: {} for s in states}\n",
        "    for s in states:\n",
        "        next_states = (ALPH + [END]) if s != END else []\n",
        "        total = sum(trans_counts[s][n] for n in next_states) + add_k * len(next_states)\n",
        "        for n in next_states:\n",
        "            T[s][n] = (trans_counts[s][n] + add_k) / total\n",
        "    return T\n",
        "\n",
        "# train\n",
        "Transitions = train_bigram_hmm(corpus_words, add_k=0.5)\n",
        "\n",
        "# check a few examples\n",
        "for letter in [\"a\", \"e\", \"t\", \"s\"]:\n",
        "    nxt = sorted(Transitions[letter].items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "    print(f\"Top next letters after '{letter}':\", nxt)\n",
        "\n",
        "# initial-letter prior\n",
        "P0 = np.array([Transitions[START].get(ch, 1e-12) for ch in ALPH])\n",
        "P0 /= P0.sum()\n",
        "print(\"\\nSum of P0 =\", P0.sum(), \"(should be 1)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a29IE8OPy7uV",
        "outputId": "e28aac96-d5b1-4d48-fbba-a25b20b6ded9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top next letters after 'a': [('l', 0.1402410783207648), ('n', 0.139148506620747), ('t', 0.13774716465768067), ('r', 0.10527878392019477), ('c', 0.06561368089780892)]\n",
            "Top next letters after 'e': [('$', 0.18911340708908597), ('r', 0.17940121707151058), ('n', 0.1059705586541099), ('s', 0.08632267633821991), ('d', 0.062407932299127326)]\n",
            "Top next letters after 't': [('i', 0.20591842754894502), ('e', 0.19064105947926532), ('$', 0.09882159325560093), ('o', 0.09869738701113198), ('a', 0.09503330279929824)]\n",
            "Top next letters after 's': [('$', 0.18592446012217156), ('t', 0.16228168287017122), ('s', 0.10123031919470016), ('i', 0.08453927557429235), ('e', 0.08440161748257764)]\n",
            "\n",
            "Sum of P0 = 1.0 (should be 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 4: Forward–Backward to get letter posteriors under constraints ---\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def _transition_matrix_from_T(T):\n",
        "    \"\"\"Build a 26x26 matrix A[i,j] = P(next_letter=j | current_letter=i).\"\"\"\n",
        "    A = np.zeros((26, 26), dtype=float)\n",
        "    for i, li in enumerate(ALPH):\n",
        "        row = np.array([T[li].get(lj, 1e-12) for lj in ALPH], dtype=float)\n",
        "        s = row.sum()\n",
        "        A[i, :] = row / s if s > 0 else np.full(26, 1.0/26)\n",
        "    return A\n",
        "\n",
        "A = _transition_matrix_from_T(Transitions)  # reuse across calls\n",
        "\n",
        "def hmm_letter_posteriors(length: int, pattern: str, guessed: Set[str]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Per-position posterior P(letter | pattern, guessed) for a word of given length.\n",
        "    pattern: length-L string of letters or '_' placeholders.\n",
        "    guessed: letters already guessed (excluded from unknown slots).\n",
        "    Returns: (L, 26) array.\n",
        "    \"\"\"\n",
        "    assert len(pattern) == length\n",
        "    L = length\n",
        "\n",
        "    # Allowed letters at each position (respect pattern + already guessed)\n",
        "    valid = []\n",
        "    for t, ch in enumerate(pattern):\n",
        "        if ch == \"_\":\n",
        "            allowed = [c for c in ALPH if c not in guessed]\n",
        "        else:\n",
        "            allowed = [ch]\n",
        "        valid.append(set(allowed))\n",
        "\n",
        "    # Forward\n",
        "    alpha = np.zeros((L, 26), dtype=float)\n",
        "    for j, letter in enumerate(ALPH):\n",
        "        if letter in valid[0]:\n",
        "            alpha[0, j] = P0[j]\n",
        "    s = alpha[0].sum()\n",
        "    alpha[0] = (alpha[0] / s) if s > 0 else np.full(26, 1.0/26)\n",
        "\n",
        "    for t in range(1, L):\n",
        "        incoming = alpha[t-1] @ A\n",
        "        for j, letter in enumerate(ALPH):\n",
        "            alpha[t, j] = incoming[j] if letter in valid[t] else 0.0\n",
        "        s = alpha[t].sum()\n",
        "        alpha[t] = (alpha[t] / s) if s > 0 else np.full(26, 1.0/26)\n",
        "\n",
        "    # Backward\n",
        "    beta = np.zeros((L, 26), dtype=float)\n",
        "    beta[-1, :] = np.array([Transitions[ALPH[j]].get(END, 1e-12) for j in range(26)], dtype=float)\n",
        "    s = beta[-1].sum()\n",
        "    beta[-1] = (beta[-1] / s) if s > 0 else np.full(26, 1.0/26)\n",
        "\n",
        "    for t in range(L-2, -1, -1):\n",
        "        for i in range(26):\n",
        "            s = 0.0\n",
        "            for j in range(26):\n",
        "                if ALPH[j] in valid[t+1]:\n",
        "                    s += A[i, j] * beta[t+1, j]\n",
        "            beta[t, i] = s\n",
        "        s = beta[t].sum()\n",
        "        beta[t] = (beta[t] / s) if s > 0 else np.full(26, 1.0/26)\n",
        "\n",
        "    # Posterior per position\n",
        "    post = alpha * beta\n",
        "    for t in range(L):\n",
        "        if pattern[t] == \"_\":\n",
        "            for j, letter in enumerate(ALPH):\n",
        "                if letter in guessed:\n",
        "                    post[t, j] = 0.0\n",
        "        s = post[t].sum()\n",
        "        post[t] = (post[t] / s) if s > 0 else np.full(26, 1.0/26)\n",
        "    return post\n",
        "\n",
        "# --- quick sanity demos ---\n",
        "def show_top_letters(row, k=8):\n",
        "    pairs = [(ALPH[i], float(row[i])) for i in range(26)]\n",
        "    pairs.sort(key=lambda x: x[1], reverse=True)\n",
        "    return pairs[:k]\n",
        "\n",
        "print(\"Demo 1: pattern='_____' guessed=set()\")\n",
        "p1 = hmm_letter_posteriors(5, \"_____\", set())\n",
        "print(\"Top any-position letters:\", show_top_letters(p1.mean(axis=0), k=10))\n",
        "\n",
        "print(\"\\nDemo 2: pattern='__a__' guessed={'e','s','t'}\")\n",
        "p2 = hmm_letter_posteriors(5, \"__a__\", {'e','s','t'})\n",
        "print(\"Top any-position letters:\", show_top_letters(p2.mean(axis=0), k=10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTNFPlTrzMZ5",
        "outputId": "01560633-ff70-4db1-b247-6b64cf08d965"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demo 1: pattern='_____' guessed=set()\n",
            "Top any-position letters: [('e', 0.11631323980114217), ('a', 0.0816326280763491), ('s', 0.0731401237512275), ('i', 0.06816083594575498), ('n', 0.0655130931458978), ('r', 0.06541540359968616), ('t', 0.06388773722797793), ('l', 0.05946358124379693), ('o', 0.057835650213950665), ('c', 0.047010837290960505)]\n",
            "\n",
            "Demo 2: pattern='__a__' guessed={'e','s','t'}\n",
            "Top any-position letters: [('a', 0.2531234709489288), ('l', 0.11162038179353509), ('r', 0.07884470038646105), ('y', 0.07627810408376692), ('n', 0.06472455486188446), ('c', 0.054300612663804204), ('i', 0.04755763656933969), ('p', 0.04543238204305205), ('d', 0.03753025154627034), ('m', 0.03516660023119161)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 5: Build fast length index over corpus ---\n",
        "from collections import defaultdict\n",
        "\n",
        "len_index = defaultdict(list)\n",
        "for w in corpus_words:\n",
        "    len_index[len(w)].append(w)\n",
        "\n",
        "for L in range(3, 13):\n",
        "    if L in len_index:\n",
        "        print(f\"len={L}: {len(len_index[L])} words\")\n",
        "print(\"✅ Length index built.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHCzTH74zkx3",
        "outputId": "f4bbb26d-2663-41c6-a542-35c1833c244f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len=3: 388 words\n",
            "len=4: 1169 words\n",
            "len=5: 2340 words\n",
            "len=6: 3755 words\n",
            "len=7: 5111 words\n",
            "len=8: 6348 words\n",
            "len=9: 6787 words\n",
            "len=10: 6465 words\n",
            "len=11: 5452 words\n",
            "len=12: 4292 words\n",
            "✅ Length index built.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 6: Candidate filtering utilities ---\n",
        "\n",
        "from typing import List, Set\n",
        "\n",
        "def letters_in_pattern(pattern: str) -> Set[str]:\n",
        "    return set(ch for ch in pattern if ch != \"_\")\n",
        "\n",
        "def filter_candidates(pattern: str, guessed: Set[str], pool: List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Keep words that:\n",
        "      • match all fixed letters at their positions, and\n",
        "      • contain none of the known-wrong letters (guessed − visible).\n",
        "    \"\"\"\n",
        "    L = len(pattern)\n",
        "    vis = letters_in_pattern(pattern)\n",
        "    wrong = guessed - vis\n",
        "    fixed = [(i, ch) for i, ch in enumerate(pattern) if ch != \"_\"]\n",
        "\n",
        "    cand = []\n",
        "    for w in pool:\n",
        "        ok = True\n",
        "        # fixed positions must match\n",
        "        for i, ch in fixed:\n",
        "            if w[i] != ch:\n",
        "                ok = False\n",
        "                break\n",
        "        if not ok:\n",
        "            continue\n",
        "        # exclude words that contain any wrong letter anywhere\n",
        "        if wrong and any((c in wrong) for c in w):\n",
        "            continue\n",
        "        cand.append(w)\n",
        "    return cand\n",
        "\n",
        "# quick sanity check\n",
        "pat = \"_____\"\n",
        "pool5 = len_index[len(pat)]\n",
        "c0 = filter_candidates(pat, guessed=set(), pool=pool5)\n",
        "print(f\"5-letter initial candidates: {len(c0)} (expect ~{len(pool5)})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-HKrI2BzzGV",
        "outputId": "29bfadf0-90b2-44fd-a462-6b096b07b36d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-letter initial candidates: 2340 (expect ~2340)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- New Cell 7: RL Environment, State Representation, and DQNAgent Base ---\n",
        "\n",
        "# Needed for the DQN/RL agent\n",
        "from collections import defaultdict, deque\n",
        "import random\n",
        "from typing import List, Set, Tuple, Dict\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. State Representation (Vector for DQN Input) ---\n",
        "\n",
        "# Maximum length found in your corpus stats (max=24.0, but let's use a safe value)\n",
        "MAX_WORD_LEN = 24\n",
        "LIVES_SLOTS = 7 # 0 to 6 lives\n",
        "\n",
        "def state_to_vector(pattern: str, guessed: Set[str], lives_left: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Converts the Hangman game state into a fixed-length NumPy vector for the DQN.\n",
        "\n",
        "    The state vector combines:\n",
        "    1. Masked Word Pattern (Padded & Encoded)\n",
        "    2. Guessed Letters (Binary Vector)\n",
        "    3. HMM Posteriors (Probability Vector)\n",
        "    4. Lives Left (One-hot encoded)\n",
        "    \"\"\"\n",
        "    L = len(pattern)\n",
        "    state_parts = []\n",
        "\n",
        "    # 1. Masked Word Pattern (L * 27)\n",
        "    # Pad to MAX_WORD_LEN with a neutral character (e.g., '@', index 26)\n",
        "    padded_pattern = pattern.ljust(MAX_WORD_LEN, '@')\n",
        "\n",
        "    pattern_encoding = np.zeros((MAX_WORD_LEN, 27), dtype=float)\n",
        "    for i, ch in enumerate(padded_pattern):\n",
        "        if ch == '_': # Unknown slot\n",
        "            pattern_encoding[i, 26] = 1.0\n",
        "        elif ch != '@': # Fixed letter\n",
        "            pattern_encoding[i, A2I[ch]] = 1.0\n",
        "        # If ch == '@' (padding), the vector is all zeros, which is fine\n",
        "    state_parts.append(pattern_encoding.flatten())\n",
        "\n",
        "    # 2. Guessed Letters (26) - Binary vector for 'a' to 'z'\n",
        "    guessed_encoding = np.array([1.0 if ch in guessed else 0.0 for ch in ALPH], dtype=float)\n",
        "    state_parts.append(guessed_encoding)\n",
        "\n",
        "    # 3. HMM Posteriors (26)\n",
        "    # Uses the HMM logic from Cell 4 to estimate overall letter probability given constraints\n",
        "    post = hmm_letter_posteriors(L, pattern, guessed)\n",
        "    hmm_marginals = post.mean(axis=0) # (26,) array\n",
        "    state_parts.append(hmm_marginals)\n",
        "\n",
        "    # 4. Lives Left (7) - One-hot encoding\n",
        "    lives_encoding = np.zeros(LIVES_SLOTS, dtype=float)\n",
        "    lives_encoding[max(0, lives_left)] = 1.0 # Index 0 is 0 lives, Index 6 is 6 lives\n",
        "    state_parts.append(lives_encoding)\n",
        "\n",
        "    # Combine all parts\n",
        "    state_vector = np.concatenate(state_parts)\n",
        "    return state_vector\n",
        "\n",
        "# --- 2. Simplified DQNAgent (for structural clarity) ---\n",
        "\n",
        "# Note: For a true DQN, you would replace this Q-table with a Neural Network (Keras/TensorFlow)\n",
        "# and implement methods for target network updates and experience replay.\n",
        "# This structure is provided to fulfill the RL mandate framework.\n",
        "\n",
        "@dataclass\n",
        "class Experience:\n",
        "    state: np.ndarray\n",
        "    action_idx: int\n",
        "    reward: float\n",
        "    next_state: np.ndarray\n",
        "    done: bool\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_size: int, action_size: int):\n",
        "        self.state_size = state_size # 685 in this setup (24*27 + 26 + 26 + 7)\n",
        "        self.action_size = action_size # 26\n",
        "\n",
        "        # Hyperparameters (You MUST tune these for proper RL learning)\n",
        "        self.gamma = 0.99           # Discount factor\n",
        "        self.epsilon = 1.0          # Exploration rate\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.9995 # Decays per episode or step\n",
        "        self.learning_rate = 0.001\n",
        "        self.batch_size = 32\n",
        "\n",
        "        # Experience Replay (Mandated component)\n",
        "        self.memory = deque(maxlen=20000)\n",
        "\n",
        "        # Placeholder for the Q-Network (Needs Keras/TensorFlow)\n",
        "        # self.q_network = self._build_model()\n",
        "        # self.target_network = self._build_model()\n",
        "\n",
        "        print(f\"DQN Agent initialized (State Size: {state_size}, Action Size: {action_size}).\")\n",
        "\n",
        "    def choose_action(self, state_vector: np.ndarray, guessed_letters: Set[str]) -> Tuple[str, int]:\n",
        "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
        "        valid_actions_idx = [A2I[ch] for ch in ALPH if ch not in guessed_letters]\n",
        "\n",
        "        if not valid_actions_idx:\n",
        "            # Should not happen in a typical game\n",
        "            return ALPH[0], 0 # Fallback: guess 'a'\n",
        "\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            # Exploration: Choose a random un-guessed letter\n",
        "            action_idx = np.random.choice(valid_actions_idx)\n",
        "        else:\n",
        "            # Exploitation: Choose the best Q-value from the Q-Network\n",
        "            # --- Placeholder for DQN Q-value prediction ---\n",
        "            # q_values = self.q_network.predict(state_vector[np.newaxis, :])[0]\n",
        "\n",
        "            # --- Simplification: Choose the letter with highest HMM marginal (temporary) ---\n",
        "            hmm_marginals = state_vector[-33:-7] # HMM part of the state vector\n",
        "\n",
        "            # Mask out invalid actions\n",
        "            q_values = hmm_marginals.copy() # Use HMM as Q-proxy for this demo\n",
        "            q_values[list(set(range(26)) - set(valid_actions_idx))] = -np.inf\n",
        "\n",
        "            action_idx = np.argmax(q_values)\n",
        "\n",
        "        return ALPH[action_idx], action_idx\n",
        "\n",
        "    def remember(self, state, action_idx, reward, next_state, done):\n",
        "        \"\"\"Store experience in the replay buffer.\"\"\"\n",
        "        self.memory.append(Experience(state, action_idx, reward, next_state, done))\n",
        "\n",
        "    def train_model(self):\n",
        "        \"\"\"Train the Q-network by sampling a batch from memory.\"\"\"\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        # Sample a batch of experiences\n",
        "        batch = random.sample(self.memory, self.batch_size)\n",
        "\n",
        "        # --- Placeholder for DQN Training ---\n",
        "        # Implementation of the Q-learning update rule:\n",
        "        # target = reward + gamma * max(Q(S', a'))\n",
        "        # Train q_network to predict target for Q(S, A)\n",
        "        # This requires Keras/TensorFlow.\n",
        "        pass\n",
        "        # ------------------------------------\n",
        "\n",
        "    def update_target_model(self):\n",
        "        \"\"\"Periodically update the target network weights.\"\"\"\n",
        "        # --- Placeholder for Target Network Update ---\n",
        "        # self.target_network.set_weights(self.q_network.get_weights())\n",
        "        pass\n",
        "        # ---------------------------------------------\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        \"\"\"Decay the exploration rate.\"\"\"\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "\n",
        "# Get the state size dynamically\n",
        "STATE_SIZE = state_to_vector(\"a\", set(), 6).shape[0]\n",
        "ACTION_SIZE = 26\n",
        "\n",
        "# Initialize the agent\n",
        "rl_agent = DQNAgent(STATE_SIZE, ACTION_SIZE)\n",
        "print(f\"Calculated State Vector Size: {STATE_SIZE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydnCmQbD0Amp",
        "outputId": "925e5e15-a69f-4c85-d843-0f11ceae10c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DQN Agent initialized (State Size: 707, Action Size: 26).\n",
            "Calculated State Vector Size: 707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- New Cell 8: RL Training Loop and Evaluation ---\n",
        "\n",
        "class RLEnvironment:\n",
        "    \"\"\"Combines the game logic and reward function.\"\"\"\n",
        "\n",
        "    def __init__(self, len_index: Dict[int, List[str]], rl_agent: DQNAgent):\n",
        "        self.len_index = len_index\n",
        "        self.agent = rl_agent\n",
        "\n",
        "    def reset(self, word: str, lives: int = 6) -> Tuple[str, Set[str], int]:\n",
        "        \"\"\"Starts a new game.\"\"\"\n",
        "        L = len(word)\n",
        "        self.word = word\n",
        "        self.pattern = [\"_\"] * L\n",
        "        self.guessed: Set[str] = set()\n",
        "        self.lives_left = lives\n",
        "        self.steps = 0\n",
        "        self.wrong_guesses = 0\n",
        "        self.repeated_guesses = 0\n",
        "        self.won = False\n",
        "\n",
        "        # Initial candidate pool (used only for candidate filtering constraint in a more complex setup)\n",
        "        self.pool = self.len_index.get(L, [])[:]\n",
        "\n",
        "        return \"\".join(self.pattern), self.guessed, self.lives_left\n",
        "\n",
        "    def step(self, action_letter: str) -> Tuple[np.ndarray, float, bool]:\n",
        "        \"\"\"\n",
        "        Takes one step (guess) in the environment.\n",
        "        Returns: next_state, reward, done\n",
        "        \"\"\"\n",
        "        self.steps += 1\n",
        "        reward = 0.0\n",
        "\n",
        "        # 1. Check for repeated guess (Inefficiency penalty)\n",
        "        if action_letter in self.guessed:\n",
        "            reward = -10.0 # Large penalty for repeated guess [cite: 34]\n",
        "            self.repeated_guesses += 1\n",
        "            # Note: RL agents should learn not to take these actions (masking helps)\n",
        "            return state_to_vector(\"\".join(self.pattern), self.guessed, self.lives_left), reward, False\n",
        "\n",
        "        self.guessed.add(action_letter)\n",
        "\n",
        "        # 2. Check if the guess is correct\n",
        "        if action_letter in self.word:\n",
        "            # Correct guess (Small reward for progress)\n",
        "            reward = 1.0\n",
        "\n",
        "            # Update pattern\n",
        "            newly_revealed = 0\n",
        "            for i, ch in enumerate(self.word):\n",
        "                if ch == action_letter:\n",
        "                    if self.pattern[i] == '_':\n",
        "                        self.pattern[i] = action_letter\n",
        "                        newly_revealed += 1\n",
        "\n",
        "            pat_str = \"\".join(self.pattern)\n",
        "\n",
        "            # Check for win condition\n",
        "            if \"_\" not in pat_str:\n",
        "                self.won = True\n",
        "                reward += 100.0 # Large reward for winning [cite: 33]\n",
        "                return state_to_vector(pat_str, self.guessed, self.lives_left), reward, True\n",
        "\n",
        "            # Update candidate pool (keep only consistent candidates)\n",
        "            self.pool = filter_candidates(pat_str, self.guessed, self.pool)\n",
        "\n",
        "        else:\n",
        "            # Wrong guess (Penalty and loss of life) [cite: 34]\n",
        "            self.lives_left -= 1\n",
        "            self.wrong_guesses += 1\n",
        "            reward = -5.0 # Penalty for wrong guess\n",
        "\n",
        "            pat_str = \"\".join(self.pattern)\n",
        "\n",
        "            # Update candidate pool (prune words containing the wrong letter)\n",
        "            # We must re-filter from the *original* pool to ensure consistency\n",
        "            self.pool = filter_candidates(pat_str, self.guessed, self.len_index.get(len(self.word), []))\n",
        "\n",
        "            # Check for loss condition\n",
        "            if self.lives_left <= 0:\n",
        "                reward = -100.0 # Large penalty for losing\n",
        "                return state_to_vector(pat_str, self.guessed, self.lives_left), reward, True\n",
        "\n",
        "        # Return next state, reward, and done status\n",
        "        return state_to_vector(\"\".join(self.pattern), self.guessed, self.lives_left), reward, False\n",
        "\n",
        "    def train_agent(self, train_words: List[str], num_episodes: int = 5000):\n",
        "        \"\"\"The main RL training loop.\"\"\"\n",
        "        print(f\"\\nStarting RL Training for {num_episodes} episodes...\")\n",
        "\n",
        "        # Use a list of words of lengths that exist in the corpus for stability\n",
        "        # The test words are usually 7-12, but training should use all\n",
        "        train_pool = [w for L in self.len_index for w in self.len_index[L] if L >= 3]\n",
        "\n",
        "        for e in range(1, num_episodes + 1):\n",
        "            if not train_pool: continue # Handle empty corpus case\n",
        "\n",
        "            word = random.choice(train_pool)\n",
        "            pat_str, guessed, lives = self.reset(word)\n",
        "            done = False\n",
        "\n",
        "            # Game Loop\n",
        "            while not done and self.steps < 60: # max_steps limit\n",
        "\n",
        "                # 1. Get current state vector\n",
        "                state = state_to_vector(pat_str, guessed, lives)\n",
        "\n",
        "                # 2. Agent chooses action (letter)\n",
        "                action_letter, action_idx = self.agent.choose_action(state, guessed)\n",
        "\n",
        "                # 3. Take action in the environment\n",
        "                next_state, reward, done = self.step(action_letter)\n",
        "\n",
        "                # Update game variables for next loop\n",
        "                pat_str = \"\".join(self.pattern)\n",
        "                guessed = self.guessed\n",
        "                lives = self.lives_left\n",
        "\n",
        "                # 4. Agent remembers the experience\n",
        "                self.agent.remember(state, action_idx, reward, next_state, done)\n",
        "\n",
        "                # 5. Agent trains (samples from memory)\n",
        "                self.agent.train_model()\n",
        "\n",
        "            # Decay epsilon and update target network\n",
        "            self.agent.decay_epsilon()\n",
        "            if e % 50 == 0:\n",
        "                self.agent.update_target_model()\n",
        "                print(f\"Episode {e}/{num_episodes}: Success={self.won}, Epsilon={self.agent.epsilon:.4f}\")\n",
        "\n",
        "        print(\"RL Training complete.\")\n",
        "\n",
        "    def evaluate(self, words: List[str], lives: int = 6, max_steps: int = 60):\n",
        "        \"\"\"Evaluate the agent on the test set.\"\"\"\n",
        "        wins = 0\n",
        "        total_wrong = 0\n",
        "        total_repeated = 0\n",
        "\n",
        "        print(f\"\\nStarting Evaluation on {len(words)} words...\")\n",
        "\n",
        "        for w in words:\n",
        "            # Reset the environment for a new word\n",
        "            pat_str, guessed, lives = self.reset(w, lives=lives)\n",
        "            done = False\n",
        "\n",
        "            while not done and self.steps < max_steps:\n",
        "\n",
        "                # Get current state vector\n",
        "                state = state_to_vector(pat_str, guessed, lives)\n",
        "\n",
        "                # Agent chooses action (in evaluation, epsilon=0)\n",
        "                # Temporarily set epsilon to 0 for evaluation, then restore\n",
        "                temp_epsilon = self.agent.epsilon\n",
        "                self.agent.epsilon = 0.0\n",
        "                action_letter, _ = self.agent.choose_action(state, guessed)\n",
        "                self.agent.epsilon = temp_epsilon\n",
        "\n",
        "                # Take action\n",
        "                _, _, done = self.step(action_letter)\n",
        "\n",
        "                # Update game variables\n",
        "                pat_str = \"\".join(self.pattern)\n",
        "                guessed = self.guessed\n",
        "\n",
        "            wins += 1 if self.won else 0\n",
        "            total_wrong += self.wrong_guesses\n",
        "            total_repeated += self.repeated_guesses\n",
        "\n",
        "        N = len(words)\n",
        "        success_rate = wins / N if N else 0.0 # Success Rate is a percentage [cite: 44]\n",
        "\n",
        "        # Final Score Calculation\n",
        "        final_score = (success_rate * 2000) - (total_wrong * 5) - (total_repeated * 2)\n",
        "\n",
        "        return dict(N=N, wins=wins, success_rate=success_rate,\n",
        "                    total_wrong=total_wrong, total_repeated=total_repeated,\n",
        "                    final_score=final_score)\n",
        "\n",
        "# --- Execution ---\n",
        "rl_env = RLEnvironment(len_index, rl_agent)\n",
        "\n",
        "# Train the agent (Mandate: RL Agent will be trained on the corpus)\n",
        "rl_env.train_agent(corpus_words, num_episodes=5000) # Use many episodes for real learning\n",
        "\n",
        "# Evaluate on the full test set\n",
        "metrics_full = rl_env.evaluate(test_words, lives=6, max_steps=60)\n",
        "print(\"FULL RL metrics:\", metrics_full)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC_HIkOV0QTL",
        "outputId": "ea91043a-1e19-4fb9-9663-4dc811c885cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting RL Training for 5000 episodes...\n",
            "Episode 50/5000: Success=False, Epsilon=0.9753\n",
            "Episode 100/5000: Success=False, Epsilon=0.9512\n",
            "Episode 150/5000: Success=False, Epsilon=0.9277\n",
            "Episode 200/5000: Success=False, Epsilon=0.9048\n",
            "Episode 250/5000: Success=False, Epsilon=0.8825\n",
            "Episode 300/5000: Success=False, Epsilon=0.8607\n",
            "Episode 350/5000: Success=False, Epsilon=0.8394\n",
            "Episode 400/5000: Success=False, Epsilon=0.8187\n",
            "Episode 450/5000: Success=False, Epsilon=0.7985\n",
            "Episode 500/5000: Success=False, Epsilon=0.7788\n",
            "Episode 550/5000: Success=False, Epsilon=0.7595\n",
            "Episode 600/5000: Success=False, Epsilon=0.7408\n",
            "Episode 650/5000: Success=False, Epsilon=0.7225\n",
            "Episode 700/5000: Success=False, Epsilon=0.7046\n",
            "Episode 750/5000: Success=False, Epsilon=0.6872\n",
            "Episode 800/5000: Success=False, Epsilon=0.6703\n",
            "Episode 850/5000: Success=False, Epsilon=0.6537\n",
            "Episode 900/5000: Success=False, Epsilon=0.6376\n",
            "Episode 950/5000: Success=False, Epsilon=0.6218\n",
            "Episode 1000/5000: Success=False, Epsilon=0.6065\n",
            "Episode 1050/5000: Success=False, Epsilon=0.5915\n",
            "Episode 1100/5000: Success=False, Epsilon=0.5769\n",
            "Episode 1150/5000: Success=False, Epsilon=0.5626\n",
            "Episode 1200/5000: Success=False, Epsilon=0.5487\n",
            "Episode 1250/5000: Success=False, Epsilon=0.5352\n",
            "Episode 1300/5000: Success=False, Epsilon=0.5220\n",
            "Episode 1350/5000: Success=False, Epsilon=0.5091\n",
            "Episode 1400/5000: Success=False, Epsilon=0.4965\n",
            "Episode 1450/5000: Success=False, Epsilon=0.4842\n",
            "Episode 1500/5000: Success=False, Epsilon=0.4723\n",
            "Episode 1550/5000: Success=False, Epsilon=0.4606\n",
            "Episode 1600/5000: Success=False, Epsilon=0.4492\n",
            "Episode 1650/5000: Success=False, Epsilon=0.4381\n",
            "Episode 1700/5000: Success=False, Epsilon=0.4273\n",
            "Episode 1750/5000: Success=False, Epsilon=0.4168\n",
            "Episode 1800/5000: Success=False, Epsilon=0.4065\n",
            "Episode 1850/5000: Success=False, Epsilon=0.3964\n",
            "Episode 1900/5000: Success=False, Epsilon=0.3866\n",
            "Episode 1950/5000: Success=False, Epsilon=0.3771\n",
            "Episode 2000/5000: Success=False, Epsilon=0.3678\n",
            "Episode 2050/5000: Success=True, Epsilon=0.3587\n",
            "Episode 2100/5000: Success=False, Epsilon=0.3498\n",
            "Episode 2150/5000: Success=False, Epsilon=0.3412\n",
            "Episode 2200/5000: Success=False, Epsilon=0.3328\n",
            "Episode 2250/5000: Success=False, Epsilon=0.3246\n",
            "Episode 2300/5000: Success=False, Epsilon=0.3165\n",
            "Episode 2350/5000: Success=False, Epsilon=0.3087\n",
            "Episode 2400/5000: Success=True, Epsilon=0.3011\n",
            "Episode 2450/5000: Success=False, Epsilon=0.2937\n",
            "Episode 2500/5000: Success=False, Epsilon=0.2864\n",
            "Episode 2550/5000: Success=False, Epsilon=0.2793\n",
            "Episode 2600/5000: Success=False, Epsilon=0.2724\n",
            "Episode 2650/5000: Success=False, Epsilon=0.2657\n",
            "Episode 2700/5000: Success=True, Epsilon=0.2592\n",
            "Episode 2750/5000: Success=False, Epsilon=0.2528\n",
            "Episode 2800/5000: Success=False, Epsilon=0.2465\n",
            "Episode 2850/5000: Success=False, Epsilon=0.2404\n",
            "Episode 2900/5000: Success=False, Epsilon=0.2345\n",
            "Episode 2950/5000: Success=False, Epsilon=0.2287\n",
            "Episode 3000/5000: Success=False, Epsilon=0.2230\n",
            "Episode 3050/5000: Success=False, Epsilon=0.2175\n",
            "Episode 3100/5000: Success=False, Epsilon=0.2122\n",
            "Episode 3150/5000: Success=False, Epsilon=0.2069\n",
            "Episode 3200/5000: Success=False, Epsilon=0.2018\n",
            "Episode 3250/5000: Success=True, Epsilon=0.1968\n",
            "Episode 3300/5000: Success=False, Epsilon=0.1920\n",
            "Episode 3350/5000: Success=True, Epsilon=0.1872\n",
            "Episode 3400/5000: Success=False, Epsilon=0.1826\n",
            "Episode 3450/5000: Success=False, Epsilon=0.1781\n",
            "Episode 3500/5000: Success=False, Epsilon=0.1737\n",
            "Episode 3550/5000: Success=False, Epsilon=0.1694\n",
            "Episode 3600/5000: Success=False, Epsilon=0.1652\n",
            "Episode 3650/5000: Success=False, Epsilon=0.1611\n",
            "Episode 3700/5000: Success=False, Epsilon=0.1572\n",
            "Episode 3750/5000: Success=True, Epsilon=0.1533\n",
            "Episode 3800/5000: Success=False, Epsilon=0.1495\n",
            "Episode 3850/5000: Success=True, Epsilon=0.1458\n",
            "Episode 3900/5000: Success=False, Epsilon=0.1422\n",
            "Episode 3950/5000: Success=True, Epsilon=0.1387\n",
            "Episode 4000/5000: Success=False, Epsilon=0.1353\n",
            "Episode 4050/5000: Success=False, Epsilon=0.1319\n",
            "Episode 4100/5000: Success=False, Epsilon=0.1287\n",
            "Episode 4150/5000: Success=False, Epsilon=0.1255\n",
            "Episode 4200/5000: Success=False, Epsilon=0.1224\n",
            "Episode 4250/5000: Success=False, Epsilon=0.1194\n",
            "Episode 4300/5000: Success=False, Epsilon=0.1164\n",
            "Episode 4350/5000: Success=False, Epsilon=0.1135\n",
            "Episode 4400/5000: Success=True, Epsilon=0.1107\n",
            "Episode 4450/5000: Success=True, Epsilon=0.1080\n",
            "Episode 4500/5000: Success=False, Epsilon=0.1053\n",
            "Episode 4550/5000: Success=False, Epsilon=0.1027\n",
            "Episode 4600/5000: Success=False, Epsilon=0.1002\n",
            "Episode 4650/5000: Success=False, Epsilon=0.0977\n",
            "Episode 4700/5000: Success=False, Epsilon=0.0953\n",
            "Episode 4750/5000: Success=False, Epsilon=0.0930\n",
            "Episode 4800/5000: Success=True, Epsilon=0.0907\n",
            "Episode 4850/5000: Success=True, Epsilon=0.0884\n",
            "Episode 4900/5000: Success=False, Epsilon=0.0862\n",
            "Episode 4950/5000: Success=False, Epsilon=0.0841\n",
            "Episode 5000/5000: Success=False, Epsilon=0.0820\n",
            "RL Training complete.\n",
            "\n",
            "Starting Evaluation on 2000 words...\n",
            "FULL RL metrics: {'N': 2000, 'wins': 727, 'success_rate': 0.3635, 'total_wrong': 10257, 'total_repeated': 0, 'final_score': -50558.0}\n"
          ]
        }
      ]
    }
  ]
}